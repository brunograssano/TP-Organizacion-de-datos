{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a preprocessing para el arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.drop(columns = 'id_usuario',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns = ['id_usuario','nombre','id_ticket','fila'],inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"tipo_de_sala\"] = X[\"tipo_de_sala\"].astype(\"category\")\n",
    "X[\"genero\"] = X[\"genero\"].astype(\"category\")\n",
    "X[\"nombre_sede\"] = X[\"nombre_sede\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"edad\"].fillna(X[\"edad\"].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True, columns=['tipo_de_sala', 'genero', 'nombre_sede'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arbol(X_train, y_train, profundidad_maxima, criterio):\n",
    "    arbol_clasificador = tree.DecisionTreeClassifier(random_state=117, max_depth=profundidad_maxima, criterion = criterio)\n",
    "    arbol_clasificador.fit(X_train, y_train)    \n",
    "    return arbol_clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(X_test, arbol_clasificador):\n",
    "    y_pred = arbol_clasificador.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    accuracy_ = pd.Series(np.array(y_test[\"volveria\"]) == y_pred).mean()\n",
    "    return accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_arbol(arbol_clasificador, profundidad_maxima):\n",
    "    dot_data = tree.export_graphviz(arbol_clasificador, feature_names=X.columns.to_list(),  max_depth = profundidad_maxima) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.render(\"arbol de decision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_accuracies_segun_profundidad(profundidades, criterio):\n",
    "    accuracies = []\n",
    "    profundidades_maximas = []\n",
    "\n",
    "    for profundidad_maxima in profundidades:\n",
    "        arbol_clasificador = construir_arbol(X_train, y_train, profundidad_maxima, criterio)\n",
    "        y_pred = predecir(X_test, arbol_clasificador)\n",
    "        accuracy_ = accuracy(y_pred, y_test)\n",
    "\n",
    "        accuracies.append(accuracy_)\n",
    "        profundidades_maximas.append(profundidad_maxima)\n",
    "        \n",
    "    return accuracies, profundidades_maximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_accuracy_vs_profundidad(accuracy, profundidades):\n",
    "    plt.subplots(dpi = 120)\n",
    "    plt.plot(profundidades, accuracies, color='lightblue', linestyle='dashed', linewidth = 2, \n",
    "             marker='o', markerfacecolor='blue', markersize=7) \n",
    "    plt.xlabel('Profundidad del arbol')\n",
    "    plt.ylabel('Accuracy sobre train')\n",
    "    plt.title(\"Accuracy segun profundidad\")\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy segun profundidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haremos es construir y entrenar 10 árboles con el criterio de impureza de Gini de profundidades 1 a 10 y luego otros 10 árboles con el criterio de ganancia de información.\n",
    "\n",
    "Para cada uno de estos árboles calculamos el accuracy y vemos en que profundidad se alcanzó el máximo accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, profundidades = obtener_accuracies_segun_profundidad([1,2,3,4,5,6,7,8,9,10], \"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_accuracy_vs_profundidad(accuracies, profundidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, profundidades = obtener_accuracies_segun_profundidad([1,2,3,4,5,6,7,8,9,10], \"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_accuracy_vs_profundidad(accuracies, profundidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que en ambos casos el máximo accuracy se alcanzó para la profundidad 4 y por eso utilizaremos esta profundidad para estudiar las matrices de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador = construir_arbol(X_train, y_train, 4, \"gini\")\n",
    "y_pred = predecir(X_test, arbol_clasificador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador_ganancia_informacion = construir_arbol(X_train, y_train, 4, \"entropy\")\n",
    "y_pred_ganancia_informacion = predecir(X_test, arbol_clasificador_ganancia_informacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión árbol de decisión criterio de impureza de Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi =150)   \n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, vmin = 0, yticklabels=[\"Volveria\",\"No volveria\"], xticklabels=[\"Volveria\", \"No Volveria\"], ax=ax)\n",
    "ax.set_title(\"Matriz de confusión del arbol de decisión (Gini)\")\n",
    "ax.set_xlabel(\"Predicho\")\n",
    "ax.set_ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi =150)   \n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_ganancia_informacion), annot = True, vmin = 0, yticklabels=[\"Volveria\",\"No volveria\"], xticklabels=[\"Volveria\", \"No Volveria\"], ax=ax)\n",
    "ax.set_title(\"Matriz de confusion del arbol de decision (Ganancia de Información)\")\n",
    "ax.set_xlabel(\"Predicho\")\n",
    "ax.set_ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que para la mejor profundidad, el árbol conseguido por el criterio de gini es mejor. Por lo tanto estudiaremos las metricas AUC-ROC para este árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test, target_names=[\"Volveria\", \"No Voleria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarAUCROC(X_test, X_train, y_test, y_train):\n",
    "\n",
    "    fpr_cnb_test,tpr_cnb_test,thresholds_cnb_test = roc_curve(y_test, arbol_clasificador.predict_proba(X_test)[:,1])\n",
    "    fpr_cnb_train,tpr_cnb_train,thresholds_cnb_train = roc_curve(y_train, arbol_clasificador.predict_proba(X_train)[:,1])\n",
    "\n",
    "    zero_test = np.argmin(np.abs(thresholds_cnb_test))\n",
    "    zero_train = np.argmin(np.abs(thresholds_cnb_train))\n",
    "\n",
    "    plt.plot(fpr_cnb_train,tpr_cnb_train,label=\"ROC Curve Decision Tree Classifier Train\")\n",
    "    plt.plot(fpr_cnb_test,tpr_cnb_test,label=\"ROC Curve Decision Tree Classifier Test\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.plot(fpr_cnb_test[zero_test],tpr_cnb_test[zero_test],'o',markersize=10,label=\"threshold zero test\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "    plt.plot(fpr_cnb_train[zero_train],tpr_cnb_train[zero_train],'x',markersize=10,label=\"threshold zero train\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "\n",
    "    plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejor profundidad por grid search AUC-ROC cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos también buscar la mejor profundidad utilizando cross validation y la métrica AUC-ROC y compararla con la que se obtuvo anteriormente utilizando accuracy. Solo consideraremos árboles construidos el criterio de gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mejor_profundidad_segun_AUCROC_CV(X, y):\n",
    "\n",
    "    mejor_auc_roc = 0\n",
    "    mejor_profundidad = None\n",
    "\n",
    "    for profundidad in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=8)\n",
    "        metricas = []\n",
    "\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "            arbol_clasificador = construir_arbol(X.iloc[train_index], y.iloc[train_index], profundidad, \"gini\")        \n",
    "            y_pred = predecir(X.iloc[test_index], arbol_clasificador)\n",
    "            auc_roc = roc_auc_score(y.iloc[test_index], y_pred)  \n",
    "            metricas.append(auc_roc)\n",
    "\n",
    "        if np.mean(metricas) >= mejor_auc_roc:\n",
    "            mejor_auc_roc = np.mean(metricas)\n",
    "            mejor_profundidad = profundidad\n",
    "            \n",
    "    return mejor_profundidad, mejor_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_profundidad, mejor_auc_roc = mejor_profundidad_segun_AUCROC_CV(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_profundidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segun esta metrica y para las profundidades de 1 a 10 la mejor profundidad es 6. Sin embargo nosotros consideramos que es mejor la profundidad obtenida con la metrica de accuracy, que fue 4. Esto es por que al ser una profundidad menor es mas interpretable, ademas la metrica de accuracy es mas interpretable que la de AUC_ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
