{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Trabajo Práctico 2: Análisis con Árbol de decisión - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las bibliotecas que se van a estar usando a lo largo de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import arbolDeDecisionPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparacion del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')\n",
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')\n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)\n",
    "\n",
    "X = arbolDeDecisionPreprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisición son algoritmos de aprendizaje supervisado utilizados para la clasificación. Se construyen iterativamente a partir de encontrar \"el mejor feature\" en cada iteración para agregar como nodo al árbol. \n",
    "\n",
    "Este feature se encuentra a partir de los criterios de impureza de Gini o de ganancia de información. Una vez encontrado el mejor feature, se agrega como nodo al árbol y luego se crean ramas para cada uno de los valores que puede tomar el feature.\n",
    "\n",
    "Finalmente, cada hoja del arbol se asociara con una clase segun la cantidad de instancias de cada clase que le hayan llegado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros que se deben definir son:\n",
    "\n",
    "**Profundidad máxima:** le impone un limite a la profundidad de máxima al árbol, los árboles muy profundos tienden a overfittear.\n",
    "\n",
    "**Criterio:** es el criterio con el que se escoge el \"mejor feature\" para ocupar un nodo. Decimos que un feature es mejor que otro si maximiza la ganancia de información o si tiene baja impureza segun el criterio de impureza Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador = DecisionTreeClassifier()\n",
    "arbol_clasificador = GridSearchCV(arbol_clasificador, {'criterion':('gini', 'entropy'), 'max_depth':[1,2,3,4,5,6,7,8,9,10]}, n_jobs = -1)\n",
    "arbol_clasificador.fit(X_train, y_train)\n",
    "y_pred = arbol_clasificador.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test, target_names=[\"Volveria\", \"No Voleria\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la matriz de confusión del árbol de decisión encontrado es muy buena. Un alto accuracy se puede ver claramente pues los valores de la diagonal invertida son significatimante menores que los de la diagonal principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 57 + 12 que el arbol predice que volverán, 57 efectivamente lo haría lo que indica un buen precision (83%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El recall es un tanto mas bajo pues de los 23 + 57 que volverían, el arbol clasifica a 57 como personas que volverían, es decir detecta un poco mas de 2/3 de las personas que volverian (71%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarROCCurve(arbol_clasificador, \"Decision Tree Classifier\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que las curvas ROC de train y test estan casi superpuestas indicando que no hay mucha diferencia entre la clasificacion sobre test y sobre train. Esto es bueno porque indica que el modelo encontrado no overfittea, probablemente debido a que la profundidad del arbol es de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(arbol_clasificador, \"Decision Tree Classifier\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un AUC score muy bueno, sobre todo considerando que el clasificador de arbol de decision es uno de los mas simples. Ademas considerando que la profundidad del arbol es de 3, el arbol es muy simple. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
