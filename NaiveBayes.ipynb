{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Naive Bayes - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las bibliotecas correspondientes a este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import categoricalNBPreprocessing\n",
    "from preprocessing import multinomialNBPreprocessing\n",
    "from preprocessing import gaussianNBPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparacion del set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos ambos set de datos, y se los pasamos a la funciones que realizan el armado hecho para el TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')\n",
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')\n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)\n",
    "X_preparado = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejorAlpha(modelo,datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_alpha = None\n",
    "    y_array=np.array(y)\n",
    "    for valor_alpha in [0.001,0.01,0.1,0.3,0.5,0.7,1,2,3,10]:\n",
    "        kf = StratifiedKFold(n_splits=2)\n",
    "        metricas = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "            modeloNB = modelo(alpha=valor_alpha)\n",
    "            modeloNB.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "            predicciones = modeloNB.predict_proba(datosPreprocesados[test_index])[:, 1]\n",
    "            score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "            metricas.append(score_obtenida)\n",
    "\n",
    "        if np.mean(metricas) >= mejor_valor:\n",
    "            mejor_valor = np.mean(metricas)\n",
    "            mejor_alpha = valor_alpha\n",
    "            \n",
    "    return mejor_valor, mejor_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejorHiperparametroGaussianNB(datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_smoothing = None\n",
    "    y_array=np.array(y)\n",
    "    for valor_smoothing in [0.00000001,0.0000001,0.000001,0.00001,0.0001,0.001]:\n",
    "        kf = StratifiedKFold(n_splits=8)\n",
    "        metricas = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "            modeloNB = GaussianNB(var_smoothing=valor_smoothing)\n",
    "            modeloNB.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "            predicciones = modeloNB.predict_proba(datosPreprocesados[test_index])[:, 1]\n",
    "            score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "            metricas.append(score_obtenida)\n",
    "\n",
    "        if np.mean(metricas) >= mejor_valor:\n",
    "            mejor_valor = np.mean(metricas)\n",
    "            mejor_smoothing = valor_smoothing\n",
    "            \n",
    "    return mejor_valor, mejor_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarAUCROC(tipo,modeloNB,X_test,X_train,y_test,y_train):\n",
    "    \n",
    "    fpr_nb_test,tpr_nb_test,thresholds_nb_test = roc_curve(y_test,modeloNB.predict_proba(X_test)[:,1])\n",
    "    fpr_nb_train,tpr_nb_train,thresholds_nb_train = roc_curve(y_train,modeloNB.predict_proba(X_train)[:,1])\n",
    "\n",
    "    zero_test = np.argmin(np.abs(thresholds_nb_test))\n",
    "    zero_train = np.argmin(np.abs(thresholds_nb_train))\n",
    "\n",
    "    plt.plot(fpr_nb_train,tpr_nb_train,label=\"ROC Curve \"+tipo+\" NB Train\")\n",
    "    plt.plot(fpr_nb_test,tpr_nb_test,label=\"ROC Curve  \"+tipo+\" NB Test\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.plot(fpr_nb_test[zero_test],tpr_nb_test[zero_test],'o',markersize=10,label=\"threshold zero test\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "    plt.plot(fpr_nb_train[zero_train],tpr_nb_train[zero_train],'x',markersize=10,label=\"threshold zero train\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo es utilizado para problemas de clasificacion en los que se tienen variables categoricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos realizando el preprocesamiento a los datos. En este caso consiste en deshacernos de las variables con datos numericos (ej. precio, edad) y codificar ordinalmente el resto de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categoricalNB = categoricalNBPreprocessing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busqueda de hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a hiperparametros, los modelos de Naive Bayes son simples, ya que solamente tienen un solo hiperparametro importante, siendo este el alpha. El alpha indica cuanto smoothing se le va a estar aplicando a los diferentes casos, de forma tal de no tener casos con probabilidad 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejor_valor, mejor_alpha = obtenerMejorAlpha(CategoricalNB,X_categoricalNB) \n",
    "# Tira el index out of bounds (index 6 is out of bounds for axis 1 with size 6)\n",
    "\n",
    "#categoricalNBCV = GridSearchCV(CategoricalNB(), {'alpha':[0.001,0.01,0.1,0.3,0.5,0.7,1,2,3,10]}, n_jobs = -1)\n",
    "#categoricalNBCV.fit(X_categoricalNB, y)\n",
    "#categoricalNBCV.predict(X_categoricalNB)\n",
    "#categoricalNBCV.best_params_\n",
    "# Tira el index out of bounds tambien con esto :C (index 6 is out of bounds for axis 1 with size 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor = 1\n",
    "mejor_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacion de las metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el set de datos y creamos el modelo con el valor de alpha obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_categoricalNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalNB = CategoricalNB(alpha=mejor_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos ahora las predicciones correspondientes con la parte de entrenamiento y la de pruebas, una vez hecho eso, mostramos las metricas obtenidas en cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = categoricalNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Categorical\",categoricalNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que en este caso la curva de evaluacion resulta mejor que la de entrenamiento, indicando que se generalizo mejor. Esto se debe a que se acerca mucho mas hacia la esquina superior izquierda del grafico. (Su area esta mas cerca de 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(categoricalNB,\"Categorical NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos guardamos las probabilidades que predice este modelo, ya que las usaremos mas adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_categorical = categoricalNB.predict_proba(X_train)\n",
    "probabilidades_x_test_categorical = categoricalNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos de manera similar para Multinomial Naive Bayes. Este caso solamente difiere en que este modelo se utiliza para features discretos. Por lo que sacamos los atributos que no sirven para este caso y codificamos el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multinomialNB = multinomialNBPreprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_alpha = obtenerMejorAlpha(MultinomialNB,X_multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo obtenido el mejor alpha para el Multinomial Naive Bayes, procedemos a desarrollarlo en mas detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_multinomialNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB = MultinomialNB(alpha=mejor_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos devuelta las predicciones de la parte de evaluacion pero con este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multinomialNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, se obtuvieron en la mayoria de las metricas valores cercanos al 80% para ambas predicciones hechas. Vemos la matriz de confusion ahora y el area bajo la curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Multinomial\",multinomialNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que devuelta la curva de evaluacion tiene mejor forma que la de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(multinomialNB,\"Multinomial NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso obtuvimos rendimientos bastante similares al del CategoricalNB, estando ligeramente abajo por unas milesimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_multinomial = multinomialNB.predict_proba(X_train)\n",
    "probabilidades_x_test_multinomial = multinomialNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora con Gaussian Naive Nayes. Este modelos es para features continuos, por lo que en su preprocesamiento nos quedaremos solamente con ese tipo de variables. Al realizar esto, no esperamos que este modelo tenga un gran rendimiento, ya que estaria considerando una parte reducida de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gaussianNB = gaussianNBPreprocessing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos el hiperparametro que tiene este modelo. (var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_var_smoothing = obtenerMejorHiperparametroGaussianNB(X_gaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor var_smoothing obtenido fue: {mejor_var_smoothing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussianNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB = GaussianNB(var_smoothing = mejor_var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos lo realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gaussianNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Gaussian\",gaussianNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que en este caso se tuvo una curva mucho peor que en los anteriores casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(gaussianNB,\"Gaussian NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que se obtuvo un valor muy bajo. Esto era esperable, ya que se estan analizando muy pocas variables al considerar solamente las continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_gaussian = gaussianNB.predict_proba(X_train)\n",
    "probabilidades_x_test_gaussian = gaussianNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Ensamble\" de Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que sklearn tiene la limitacion de que no permite trabajar a la vez con variables categoricas y variables continuas, decidimos realizar un ensamble al que le pasamos las probabilidades de los 3 modelos hechos anteriormente. De esta forma, logramos obtener un modelo de Naive Bayes que trabaje con ambos tipos de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos uniendo las probabilidades obtenidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_x_train = np.hstack((probabilidades_multinomial, probabilidades_categorical , probabilidades_gaussian))\n",
    "probabilidades_x_test = np.hstack((probabilidades_x_test_multinomial, probabilidades_x_test_categorical , probabilidades_x_test_gaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_var_smoothing = obtenerMejorHiperparametroGaussianNB(X_gaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor var_smoothing obtenido fue: {mejor_var_smoothing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_gaussiano = GaussianNB(var_smoothing = mejor_var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_gaussiano.fit(probabilidades_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensamble_gaussiano.predict(probabilidades_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(ensamble_gaussiano,\"Ensamble Gaussiano NB\",probabilidades_x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo hecho el ensamble, observamos que no se tuvieron grandes diferencias en comparacion al Multinomial y Categorical, estando este tipo de ensamble en el medio. Lo que si mejoro notablemente es su rendimiento en comparacion al Gaussian NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion de analisis: estudio del algoritmo y cuales son los features mas relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de Naive Bayes debe calcular, a priori, las probabilidades de que una instancia pertenezca a una clase. Esto lo hace con la variable target, las \"etiquetas\" del set de entrenamiento. De esta manera si inicialmente tenemos mas instancias de una clase que de otra tendremos mas probabilidad de clasificarla de esa clase mayoritaria, al menos a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(categoricalNB.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(multinomialNB.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, dado que hemos entrenado ambos modelos con la misma informacion acerca de la variable target las probabilidades a prior son las mismas en cada modelo. Podemos ver que casi dos tercios de la instancias son de la clase \"No volveria\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = X_preparado.drop(columns=['edad', 'precio_ticket', 'autocompletamos_edad']).columns.to_list()\n",
    "features_gaussian = ['edad','precio_ticket','autocompletamos_edad']\n",
    "features_multinomial = X_preparado.drop(columns=['edad', 'autocompletamos_edad']).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos ahora informacion acerca de las probabilidades condicionales que se construyeron en el modelo. Analizaremos algunas para poder ver si se corresponden con el analisis realizado en la primer parte del trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for array in categoricalNB.feature_log_prob_:\n",
    "    \n",
    "    feature = features_categorical[i]\n",
    "    for probabilidad in array:\n",
    "        print(feature)\n",
    "        if(j % 2 == 0):\n",
    "            print(\"Dado que no volveria\")\n",
    "        else:\n",
    "            print(\"Dado que volveria\")\n",
    "        print(np.exp(probabilidad))\n",
    "        print(\"\")\n",
    "        j=j+1\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las probabilidades anteriores son las probabilidades condicionales. Condicionado al subconjunto de las personas que volverian o no volverian se calcula para cada feature la probabilidad de que tome alguno de los valores que puede tomar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede calcular utilizando pandas, por ejemplo para el caso del genero: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(columns = ['volveria'], data = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_volveria = X_preparado.iloc[y_df.loc[y_df[\"volveria\"] == True].index]\n",
    "X_volveria[\"genero\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_volveria = X_preparado.iloc[y_df.loc[y_df[\"volveria\"] == False].index]\n",
    "X_no_volveria[\"genero\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que dentro de las personas que volverian, el 70% es mujer y dentro de las personas que no vuelven el 84% es hombre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este feature es bastante relevante. Por ejemplo, suponiendo que consideramos solo este feature realizariamos las siguientes predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si es hombre:\n",
    "* $P$(vuelve)    = $P_{a priori}$(vuelve) * $P$(hombre|vuelve) = 0.38 * 0.30 = 0.114\n",
    "* $P$(no vuelve) = $P_{a priori}$(no vuelve) * $P$(hombre|no vuelve) = 0.62 * 0.84 = 0.52\n",
    "    \n",
    "P(vuelve) < P(no vuelve) => si es hombre no vuelve\n",
    "    \n",
    "Si es mujer: \n",
    "* $P$(vuelve) = $P_{a priori}$(vuelve) * $P$(mujer|vuelve) = 0.38 * 0.69 = 0.26\n",
    "* $P$(no vuelve) = $P_{a priori}$(no vuelve) * $P$(mujer|no vuelve) = 0.62 * 0.15 = 0.093\n",
    "    \n",
    "    P(vuelve) > P(no vuelve) => si es mujer vuelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que relativamente las probabilidades son muy distintas: para los hombres, la probabilidad de que vuelva es aproximadamente 3 veces mayor que de que no vuelva y para las mujeres lo contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por este motivo consideramos que debe ser un feature relevante a la hora de clasificar a una persona en si esta volveria o no al cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y preparamos el nuevo archivo realizando el mismo preprocesamiento realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.read_csv('Datasets/tp-2020-2c-holdout-cols2.csv')\n",
    "holdout = prepararSetDeHoldout(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_categorical_NB = categoricalNBPreprocessing(holdout)\n",
    "holdout_multinomial_NB = multinomialNBPreprocessing(holdout)\n",
    "holdout_gaussian_NB = gaussianNBPreprocessing(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_holdout_categorical = categoricalNB.predict(holdout_categorical_NB)\n",
    "predicciones_holdout_multinomial = multinomialNB.predict(holdout_multinomial_NB)\n",
    "predicciones_holdout_gaussian = gaussianNB.predict(holdout_gaussian_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escribirPrediccionesAArchivo(predicciones_holdout_categorical,\"Categorical NB\")\n",
    "escribirPrediccionesAArchivo(predicciones_holdout_multinomial,\"Multinomial NB\")\n",
    "escribirPrediccionesAArchivo(predicciones_holdout_gaussian,\"Gaussian NB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
