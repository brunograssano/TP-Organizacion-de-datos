{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Trabajo Práctico 2: Análisis con Random Forest - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las bibiliotecas que utilizaremos a lo largo del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import arbolDeDecisionPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los datos y los procesamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')\n",
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres,X_rf = arbolDeDecisionPreprocessing(X) #CREAR RF PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejoresParametros(datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_profundidad = None\n",
    "    mejor_cantidad_estimadores = None\n",
    "    mejor_criterio = None\n",
    "    y_array=np.array(y)\n",
    "    for profundidad in [1,2,3,4,5,6,7,9,10]:\n",
    "        for criterio in [\"gini\", \"entropy\"]:\n",
    "            for cantidad_estimadores in [1,10,50,100,200]:\n",
    "                kf = StratifiedKFold(n_splits=7)\n",
    "                metricas = []\n",
    "                for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "                    rf = RandomForestClassifier(criterion=criterio, max_depth=profundidad, n_estimators=cantidad_estimadores)\n",
    "                    rf.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "                    predicciones = rf.predict(datosPreprocesados[test_index])\n",
    "                    score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "                    metricas.append(score_obtenida)\n",
    "\n",
    "                if np.mean(metricas) >= mejor_valor:\n",
    "                    mejor_valor = np.mean(metricas)\n",
    "                    mejor_profundidad = profundidad\n",
    "                    mejor_criterio = criterio\n",
    "                    mejor_cantidad_estimadores = cantidad_estimadores\n",
    "            \n",
    "    return mejor_valor, mejor_profundidad, mejor_criterio, mejor_cantidad_estimadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos el set de datos en sets de training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rf, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest es un ensamble que consiste en el entrenamiento de varios clasificadores de árbol de decisión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada árbol del ensamble es construido a partir de una muestra simple con reposición del set de entrenamiento. Además se intenta forzar heterogeneidad entre los árboles al escoger el nodo principal de cada árbol a partir de un subconjunto aleatorio de los features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la implementación de sci-kit learn, cada árbol indica la probabilidad de un feature de pertenecer a una clase. Para la predicción final se promedian estas probabilidades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros que se deben definir son:\n",
    "\n",
    "**Profundidad máxima:** le impone un limite a la profundidad de máxima de cada árbol, los árboles muy profundos tienden a overfittear.\n",
    "\n",
    "**Criterio:** es el criterio con el que se escoge el \"mejor feature\" para ocupar un nodo. Decimos que un feature es mejor que otro si maximiza la ganancia de información o si tiene baja impureza segun el criterio de impureza Gini.\n",
    "\n",
    "**Cantidad de estimadores:** es la cantidad de árboles que se entrenarán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_profundidad, mejor_criterio, mejor_cantidad_estimadores = obtenerMejoresParametros(X_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {mejor_valor}\")\n",
    "print(f\"La profundidad encontrada que maximiza el AUC fue: {mejor_profundidad}\")\n",
    "print(f\"El criterio encontrado que maximiza el AUC fue: {mejor_criterio}\")\n",
    "print(f\"La cantidad de estimadores que maximizan el AUC fue: {mejor_cantidad_estimadores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=mejor_profundidad, random_state=0, n_estimators = mejor_cantidad_estimadores, criterion=mejor_criterio)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el random forest entrenado tiene un muy buen accuracy pues lo valores en la diagonal principal son mucho mayores que los de la diagonal invertida.\n",
    "\n",
    "Se puede observar que tenemos un muy buen precision tambien: de los que predecimos que volverian (55 + 6), efectivamente 55 vuelven, un 90% de precision. Por otro lado el recall no es tan bueno, de los 55 + 25 que volverian pudimos detectar que 55 volverian. Es decir que casi dos tercios de los que volverian los clasificamos correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarROCCurve(rf,\"Random Forest\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse, la curva ROC sobre el set de entrenamiento es mas cercana a la ideal que aquella sobre el set de test, sin embargo esta diferencia no es tan grande, ambas curvas son bastante similares y ademas muy buenas, su area bajo la curva debe ser cercano a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(rf,\"Random Forest\",X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos ahora las predicciones del nuevo archivo entregado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.read_csv('Datasets/tp-2020-2c-holdout-cols2.csv')\n",
    "holdout = prepararSetDeHoldout(holdout)\n",
    "nombres, holdout_rf = arbolDeDecisionPreprocessing(holdout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_holdout = rf.predict(holdout_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escribirPrediccionesAArchivo(rf,\"Random Forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
