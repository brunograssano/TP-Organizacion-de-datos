{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Trabajo Práctico 2: Análisis con Árbol de decisión - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las bibliotecas que se van a estar usando a lo largo de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import expansionDelDataset\n",
    "from preprocessing import conversionAVariablesNumericas\n",
    "from preprocessing import conversionAVariablesNumericasNormalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo\n",
    "from funcionesAuxiliares import obtenerDatasets\n",
    "from funcionesAuxiliares import obtenerHoldout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación del set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = obtenerDatasets()\n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisición son algoritmos de aprendizaje supervisado utilizados para la clasificación. Se construyen iterativamente a partir de encontrar \"el mejor feature\" en cada iteración para agregar como nodo al árbol. \n",
    "\n",
    "Este feature se encuentra a partir de los criterios de impureza de Gini o de ganancia de información. Una vez encontrado el mejor feature, se agrega como nodo al árbol y luego se crean ramas para cada uno de los valores que puede tomar el feature.\n",
    "\n",
    "Finalmente, cada hoja del árbol se asociará con una clase según la cantidad de instancias de cada clase que le hayan llegado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros que se deben definir son:\n",
    "\n",
    "**Profundidad máxima:** le impone un limite a la profundidad de máxima al árbol, los árboles muy profundos tienden a overfittear.\n",
    "\n",
    "**Criterio:** es el criterio con el que se escoge el \"mejor feature\" para ocupar un nodo. Decimos que un feature es mejor que otro si maximiza la ganancia de información o si tiene baja impureza según el criterio de impureza Gini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos dos árboles clasificadores: un primer árbol utilizando un preprocesamineto que convierte las variables categóricas a numéricas y un segundo árbol utilizando un preprocesamineto que además las normaliza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori, esperamos que los estos árboles sean similares, pues normalizar los valores en un árbol cambia el criterio de corte de sus nodos pero no hay cálculos de distancias, por lo que el árbol no es afectado notablemente por no normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalizado = conversionAVariablesNumericasNormalizadas(X)\n",
    "nombre_de_los_features, X_sin_normalizar = conversionAVariablesNumericas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sin_normalizar, y, test_size=0.25, random_state=0)\n",
    "X_normalizado_train, X_normalizado_test, y_normalizado_train, y_normalizado_test = train_test_split(X_normalizado, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol con datos de entrenamiento sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador = DecisionTreeClassifier()\n",
    "arbol_clasificador = GridSearchCV(arbol_clasificador, {'criterion':('gini', 'entropy'), 'max_depth':[1,2,3,4,5,6,7,8,9,10]}, n_jobs = -1)\n",
    "arbol_clasificador.fit(X_train, y_train)\n",
    "y_pred = arbol_clasificador.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol con datos de entrenamiento normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador_normalizado = DecisionTreeClassifier()\n",
    "arbol_clasificador_normalizado = GridSearchCV(arbol_clasificador_normalizado, {'criterion':('gini', 'entropy'), 'max_depth':[1,2,3,4,5,6,7,8,9,10]}, n_jobs = -1)\n",
    "arbol_clasificador_normalizado.fit(X_normalizado_train, y_normalizado_train)\n",
    "y_pred_normalizado = arbol_clasificador_normalizado.predict(X_normalizado_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador_normalizado.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_test, target_names=[\"Volveria\", \"No Voleria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_normalizado, y_test, target_names=[\"Volveria\", \"No Voleria\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los árboles conseguidos son iguales en sus métricas, en su profundidad y en el criterio de división en nodos. Es decir, son similares, tal como se había predicho. Por lo tanto en, lo siguiente se utilizará el árbol sin normalizar, pues es mas fácil de interpretar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la matriz de confusión del árbol de decisión sin normalizar encontrado es muy buena. Un alto accuracy se puede ver claramente pues los valores de la diagonal invertida son significativamente menores que los de la diagonal principal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 57 + 12 que el árbol predice que volverán, 57 efectivamente lo haría lo que indica un buen precision (83%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El recall es un tanto mas bajo pues de los 23 + 57 que volverían, el árbol clasifica a 57 como personas que volverían, es decir detecta un poco mas de 2/3 de las personas que volverían (71%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarROCCurve(arbol_clasificador, \"Decision Tree Classifier\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que las curvas ROC de train y test están casi superpuestas indicando que no hay mucha diferencia entre la clasificacón sobre test y sobre train. Esto es bueno porque indica que el modelo encontrado no overfittea, probablemente debido a que la profundidad del árbol es de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(arbol_clasificador, \"Decision Tree Classifier\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un AUC score muy bueno, sobre todo considerando que el clasificador de árbol de decisión es uno de los mas simples. Además considerando que la profundidad del árbol es de 3, el árbol es muy simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansión del Análisis: ¿Cuáles son los features mas relevantes para decidir si alguien volvería o no a ver la película?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó anteriormente, una de las ventajas del árbol de decisión es su fácil interpretabilidad. Al observar el árbol podremos darnos una idea de cuáles son los features que mejor separan a las clases y que permiten una buena clasificación. Esto se debe a que para agregar un feature a los nodos del árbol este debe ser aquel que maximice la ganancia de información o la pureza de Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador = DecisionTreeClassifier(criterion= 'gini', max_depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(arbol_clasificador, class_names=[\"No Volveria\", \"Volveria\"], feature_names=nombre_de_los_features) \n",
    "graph = graphviz.Source(dot_data, format='png')\n",
    "graph.render(\"Arbol de decision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Arbol de decision.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperabamos, y en concordancia con el análisis realizado en la primera parte del trabajo, se puede observar que el feature mas relevante es el **género**, pues ocupa el nodo raíz del árbol. Podemos ver claramente que es un feature muy bueno pues produce una división entre clases muy buena:\n",
    "\n",
    "* De las 58 + 154 mujeres encuestadas, 154 volverían\n",
    "* De los 315 + 73 hombres encuestados, 315 no volverían\n",
    "    \n",
    "Lo cuál claramente indica que las mujeres tienden a volver y los hombres no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además inicialmente podemos ver que de 600 personas encuestadas, 373 no volverían y 227 sí lo harían, lo cual indica que existe un leve desbalance entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, podemos ver, tal como habíamos visto que la **edad** es influyente a la hora decidir volver a ver la película en el caso de los hombres, (habíamos analizado que las mujeres tendían a volver independientemente de su edad en el análisis exploratorio). Esto se puede ver en el árbol porque el subárbol izquierdo (el correspondiente a los hombres) tiene en cuenta la edad para realizar predicciones, mientras que el subárbol derecho (el que corresponde a las mujeres) no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve también que el árbol predice que los hombres jóvenes volverían más que los mayores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las mujeres, el segundo feature que se toma en cuenta es el del tipo de sala. \n",
    "\n",
    "El árbol, considera que si una mujer fue a una **sala 4d** entonces esta no volvería y que si no fue a sala 4d entonces volvería. Si bien esta pregunta es buena para definir que una mujer volvería, pues de las 6 + 109 que no fueron a sala 4d, 109 volverían, no es tan buena para definir cuáles mujeres no volverían, pues de las 52 + 45 que fueron a sala 4d, casi la mitad, 52, no volverían. La impureza de gini es contrastante en este caso: 0.099 en el primer caso y 0.497 en el segundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis con la expansión del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos ahora mejorar la performance del modelo de árbol de decisión hallado añadiendo features mediante un preprocesado de expansión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expandido = expansionDelDataset(X)\n",
    "\n",
    "columnas_codificables_extra = ['pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "columnas_numericas_extra = ['2_clusters','4_clusters','10_clusters','cantidad_total_invitados','total_pagado']\n",
    "\n",
    "nombre_de_los_features_expandidos, X_arbol_expandido  = conversionAVariablesNumericas(X_expandido,columnas_codificables_extra,columnas_numericas_extra)\n",
    "X_expandido_train, X_expandido_test, y_expandido_train, y_expandido_test = train_test_split(X_arbol_expandido, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol con datos de entrenamiento expandidos sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador_expandido = DecisionTreeClassifier()\n",
    "arbol_clasificador_expandido = GridSearchCV(arbol_clasificador_expandido, {'criterion':('gini', 'entropy'), 'max_depth':[1,2,3,4,5,6,7,8,9,10]}, n_jobs = -1)\n",
    "arbol_clasificador_expandido.fit(X_expandido_train, y_expandido_train)\n",
    "y_pred_expandido = arbol_clasificador_expandido.predict(X_expandido_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_clasificador_expandido.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_expandido, y_test, target_names=[\"Volveria\", \"No Voleria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred_expandido,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(arbol_clasificador_expandido, \"Decision Tree Classifier\", X_expandido_test, y_expandido_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todas las métricas de este árbol mejoraron. Por lo que este es el mejor árbol que encontramos y es el que utilizaremos para realizar las predicciones de holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y preparamos el nuevo archivo realizando el mismo preprocesamiento realizado en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = obtenerHoldout()\n",
    "holdout = prepararSetDeHoldout(holdout)\n",
    "\n",
    "nombres_de_las_variables, holdout_arbol = conversionAVariablesNumericas(holdout)\n",
    "\n",
    "holdout_expandido = expansionDelDataset(holdout)\n",
    "nombre_de_los_features_expandidos, holdout_arbol_expandido  = conversionAVariablesNumericas(holdout_expandido,columnas_codificables_extra,columnas_numericas_extra)\n",
    "\n",
    "predicciones_holdout = arbol_clasificador_expandido.predict(holdout_arbol_expandido)\n",
    "escribirPrediccionesAArchivo(predicciones_holdout,\"Arbol de Decision\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
