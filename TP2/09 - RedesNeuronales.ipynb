{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Redes Neuronales - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones Iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import conversionAVariablesNormalizadas\n",
    "from preprocessing import expansionDelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import escribirPrediccionesAArchivo\n",
    "from funcionesAuxiliares import obtenerDatasets\n",
    "from funcionesAuxiliares import obtenerHoldout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación del set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los sets de datos que se usarán para el entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = obtenerDatasets() \n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarPerdidaDelModelo(historia_modelo):\n",
    "    plt.figure(dpi=125, figsize=(7, 2))\n",
    "    plt.plot(historia_modelo.history['loss'], label=\"Training loss\")\n",
    "    plt.plot(historia_modelo.history['val_loss'], label=\"Validation loss\")\n",
    "    plt.title('Loss del modelo')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModelo(modelo, epocas, tamanio_entrenamiento):\n",
    "    historia = modelo.fit(X_train, y_train, epochs=epocas, batch_size=tamanio_entrenamiento, verbose=0, validation_split=0.25)\n",
    "    return historia, modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModeloDatasetExpandido(modelo, epocas, tamanio_entrenamiento):\n",
    "    historia = modelo.fit(X_train_exp, y_train_exp, epochs=epocas, batch_size=tamanio_entrenamiento, verbose=0, validation_split=0.25)\n",
    "    return historia, modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se utiliza la de funcionesAuxiliares debido a que en este caso se tiene otro array. (en predict_proba [:,1]) (idem en mostrar el AUCScore)\n",
    "def graficarROCCurve(modelo,nombreModelo,X_test, X_train, y_test, y_train):\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, modelo.predict_proba(X_test))\n",
    "    fpr_train, tpr_train, thresholds_train = roc_curve(y_train, modelo.predict_proba(X_train))\n",
    "\n",
    "    zero_test = np.argmin(np.abs(thresholds_test))\n",
    "    zero_train = np.argmin(np.abs(thresholds_train))\n",
    "\n",
    "    plt.plot(fpr_test, tpr_test, label=\"ROC Curve \"+nombreModelo+\" Test\")\n",
    "    plt.plot(fpr_train, tpr_train, label=\"ROC Curve  \" + nombreModelo + \" Train\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.plot(fpr_test[zero_test], tpr_test[zero_test], 'o', markersize=10, label=\"threshold zero test\",\n",
    "             fillstyle=\"none\", c=\"k\", mew=2)\n",
    "    plt.plot(fpr_train[zero_train], tpr_train[zero_train], 'x', markersize=10, label=\"threshold zero train\",\n",
    "             fillstyle=\"none\", c=\"k\", mew=2)\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales están dentro de lo que se considera modelos más complejos. Este tipo de modelo dispone de una amplia cantdidad de parámetros que se pueden ir modificando hasta obtener los mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el preprocesamiento decidimos utilizar el mismo tipo de función que en otros modelos. Este preprocesamiento encodea las variables categóricas mediante OneHotEncoding y normaliza las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_redes_neuronales = conversionAVariablesNormalizadas(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_redes_neuronales, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los **parámetros** que tendremos en cuenta al entrenar las redes neuronales seran:\n",
    "\n",
    "* **Función de pérdida a optimizar:** Es la función que se busca minimizar. En nuestro caso como deseamos hacer una clasificación binaria, es decir, entre dos clases, utilizaremos siempre la función: binary cross entropy\n",
    "\n",
    "* **Optimizador:** Es el algoritmo mediante el cual se optimiza el función de perdida anterior. Utilizaremos Stochastic Gradient Descent (SGD) y Adam. La diferencia principal radica en que Adam es un optimizador que considera a la derivada segunda para realizar la optimización mientras que SGD solo la derivada primera. Esto puede llegar a suavizar la pérdida al entrenar la red a lo largo de las épocas. \n",
    "\n",
    "* **Tasa de aprendizaje:** Es un parámetro que indica la velocidad con la cual el optimizador intenta acercarse el mínimo de la función de pérdida. Una tasa pequeña, requerirá más iteraciones para alcanzar el mínimo y una muy grande podría nunca encontrarlo, por ejemplo ya que se lo saltea constantemente.\n",
    "\n",
    "* **Funcion de activacion de las neuronas:** Es la función que se aplica sobre el input de cada neurona, antes de multiplicarla por el peso correspondiente. Hemos probado las siguientes: ReLu, sigmoidea y tanh\n",
    "\n",
    "* **Cantidad de capas:** Es la cantidad de capas de la red. Consideramos que teniendo una capa de input, una oculta y una de output era suficiente. Esto es porque agregando capas el tiempo de entrenamiento se volvía poco razonable y posiblemente más complicado de lo necesario.\n",
    "\n",
    "* **Cantidad de neuronas de cada capa:** Hemos entrenado con la siguiente configuración de la red: La primera capa tiene 14 neuronas pues tenemos 14 features. La última capa tiene 1, lo cual nos servirá para realizar la clasificación en los 2. \n",
    "\n",
    "Además, en algunas redes, utilizamos **dropout:** durante el entrenamiento, algunas de las neuronas no se tienen en cuenta. Esto puede volver más robusto al modelo, al hacer que la salida del mismo no depende únicamente de un camino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estas primeras redes vamos a ir probando sin aplicar regularizacion. Luego intentaremos ver si logramos mejorar el resultado agregandole las diferentes opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos ahora armando una red neuronal sencilla para ver cómo es su desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal1 = Sequential()\n",
    "red_neuronal1.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal1.add(Dense(6, activation='tanh'))\n",
    "red_neuronal1.add(Dense(1, activation='sigmoid'))\n",
    "red_neuronal1.compile(loss='binary_crossentropy', optimizer=\"SGD\", metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el resumen de como queda armada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora finalmente entrenamos con el set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal1 = entrenarModelo(red_neuronal1, 500, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cómo se fue desarrollando la funcion de pérdida para el entrenamiento y la validación de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora buscamos las métricas que nos interesan sobre el set de evaluación guardado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal1,\"Red Neuronal 1\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal1.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales 1: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se obtuvieron resultados que estan bien, pero que pueden mejorarse. Una cosa que se destaca es que en el gráfico del entrenamiento aparece como que todavía puede seguir aprendiendo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos aumentando la cantidad de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal2 = Sequential()\n",
    "red_neuronal2.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal2.add(Dense(6, activation='tanh'))\n",
    "red_neuronal2.add(Dense(1, activation='sigmoid'))\n",
    "red_neuronal2.compile(loss='binary_crossentropy', optimizer=\"SGD\", metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal2 = entrenarModelo(red_neuronal2, 800, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal2,\"Red Neuronal 2\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal2.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que aprendió bastante más y mejoró la métrica, pero que ya en el entrenamiento se empiezan a ver picos hacia el final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos mejorarlo cambiando el optimizador a 'Adam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal3 = Sequential()\n",
    "red_neuronal3.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal3.add(Dense(6, activation='tanh'))\n",
    "red_neuronal3.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal3.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal3 = entrenarModelo(red_neuronal3, 800, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal3,\"Red Neuronal 3\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal3.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso disminuyo el valor buscado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos agregando algunas capas de 'Dropout' y bajamos las epocas a 350, así no empieza a separarse hacia el final la función de pérdida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal4 = Sequential()\n",
    "red_neuronal4.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal4.add(Dropout(0.1))\n",
    "red_neuronal4.add(Dense(6, activation='tanh'))\n",
    "red_neuronal4.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal4.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal4 = entrenarModelo(red_neuronal4, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal4,\"Red Neuronal 4\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal4.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el resultado mejoro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Buscamos probar ahora agregando una capa más junto a un dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal5 = Sequential()\n",
    "red_neuronal5.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal5.add(Dropout(0.1))\n",
    "red_neuronal5.add(Dense(14, activation='relu'))\n",
    "red_neuronal5.add(Dropout(0.1))\n",
    "red_neuronal5.add(Dense(6, activation='tanh'))\n",
    "red_neuronal5.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal5.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal5 = entrenarModelo(red_neuronal5, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal5,\"Red Neuronal 5\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal5.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo hecho esto, el valor de la métrica AUC incremento respecto a las primeras realizadas, pero no respecto a la anterior (0.877)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Red Neuronal 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo buscamos crear un modelo de redes neuronales que utilice el dataset expandido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exp = expansionDelDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_codificables_extra = ['pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "columnas_numericas_extra = ['2_clusters','4_clusters','10_clusters','cantidad_total_invitados','total_pagado']\n",
    "\n",
    "X_redes_exp = conversionAVariablesNormalizadas(X_exp,columnas_codificables_extra,columnas_numericas_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_exp, X_test_exp, y_train_exp, y_test_exp = train_test_split(X_redes_exp, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal6 = Sequential()\n",
    "red_neuronal6.add(Dense(26, input_dim=26, activation='relu'))\n",
    "red_neuronal6.add(Dropout(0.1))\n",
    "red_neuronal6.add(Dense(6, activation='tanh'))\n",
    "red_neuronal6.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal6.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal6 = entrenarModeloDatasetExpandido(red_neuronal6, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal6.predict(X_test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_exp, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarROCCurve(red_neuronal6,\"Red Neuronal 6\",X_test_exp, X_train_exp, y_test_exp, y_train_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test_exp,red_neuronal6.predict_proba(X_test_exp))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no logramos mejorar la métrica obtenida al utilizar la red neuronal 4, por lo tanto sera esa la que utilizaremos para las predicciones de holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de quedarnos con una red definitiva para las predicciones, probamos utilizar la red 4 que nos dio el mejor resultado hasta ahora con regularizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal4_regularizada = Sequential()\n",
    "red_neuronal4_regularizada.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal4_regularizada.add(Dropout(0.1))\n",
    "red_neuronal4_regularizada.add(Dense(6, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1(0.001),\n",
    "                                                          activity_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "red_neuronal4_regularizada.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal4_regularizada.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal4_regularizada = entrenarModelo(red_neuronal4_regularizada, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal4_regularizada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal4_regularizada.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No logro superar a la red sin regularizacion. Probamos devuelta tocando un poco mas los parametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal4_regularizada = Sequential()\n",
    "red_neuronal4_regularizada.add(Dense(14, input_dim=14, activation='relu'))\n",
    "red_neuronal4_regularizada.add(Dropout(0.1))\n",
    "red_neuronal4_regularizada.add(Dense(6, activation='tanh', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                                                           activity_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.01)))\n",
    "red_neuronal4_regularizada.add(Dense(1, activation='sigmoid'))\n",
    "optimizador = keras.optimizers.Adam()\n",
    "red_neuronal4_regularizada.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, red_neuronal4_regularizada = entrenarModelo(red_neuronal4_regularizada, 350, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarPerdidaDelModelo(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = red_neuronal4_regularizada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred.round(), target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_red = roc_auc_score(y_test,red_neuronal4_regularizada.predict_proba(X_test))\n",
    "print(\"AUC para redes neuronales: {:.3f}\".format(auc_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelta no logramos superar a las anterior. Aunque hay que destacar que tuvo uno mejor perdida para la validacion, manteniendose las curvas de *training* y *validation* separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y preparamos el nuevo archivo realizando el mismo preprocesamiento realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = obtenerHoldout()\n",
    "\n",
    "holdout = prepararSetDeHoldout(holdout)\n",
    "holdout_redes = conversionAVariablesNormalizadas(holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones y escribimos al archivo CSV. Para realizar las predicciones, utilizamos el modelo que mejor resultado dio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_holdout = red_neuronal4.predict(holdout_redes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escribirPrediccionesAArchivo(predicciones_holdout.round().astype(int).ravel(),\"RedesNeuronales\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
