{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Regresión logística - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibiliotecas que utilizaremos a lo largo del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import expansionDelDataset\n",
    "from preprocessing import conversionAVariablesNormalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo\n",
    "from funcionesAuxiliares import obtenerDatasets\n",
    "from funcionesAuxiliares import obtenerHoldout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los datos y los procesamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos que tenemos y llamamos a las funciones que se encargarán de dejar listos los datasets con la investigación del TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = obtenerDatasets()\n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que obtiene mediante grid search y K-Fold cross validation el tipo de regularización que maximiza la métrica de AUC ROC para el modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejoresHiperparametros(datosPreprocesados):\n",
    "    mejor_c = 0\n",
    "    mejor_valor = 0\n",
    "    mejor_regularizacion = None\n",
    "    y_array=np.array(y)\n",
    "    for regularizacion in [\"l2\",\"none\", \"l1\", \"elasticnet\"]:\n",
    "        for valor_c in [0.001,0.01,0.1,0.2,0.5,0.7,1.0,1.5,2,2.5,3,3.5,4,5]:\n",
    "            if(regularizacion == \"elasticnet\"):\n",
    "                l1_ratio = 0.5\n",
    "            else:\n",
    "                l1_ratio = None\n",
    "            kf = StratifiedKFold(n_splits=5)\n",
    "            metricas = []\n",
    "            for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "                rl = None\n",
    "                if regularizacion == \"none\": # Para evitar los warnings que surgen al mandar None con l1_ratio y C\n",
    "                    rl = LogisticRegression(penalty = regularizacion, max_iter = 5000, solver = \"saga\")\n",
    "                else:\n",
    "                    rl = LogisticRegression(penalty = regularizacion, max_iter = 5000, solver = \"saga\", l1_ratio = l1_ratio, C=valor_c)\n",
    "                rl.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "                predicciones = rl.predict_proba(datosPreprocesados[test_index])[:, 1]\n",
    "                score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "                metricas.append(score_obtenida)\n",
    "\n",
    "            if np.mean(metricas) >= mejor_valor:\n",
    "                mejor_valor = np.mean(metricas)\n",
    "                mejor_regularizacion = regularizacion\n",
    "                mejor_c = valor_c\n",
    "            \n",
    "    return mejor_valor, mejor_regularizacion, mejor_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un método de aprendizaje supervisado sencillo el cual consiste en obtener una curva logística que sirva para predecir la clase de una instancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el procesamiento de los datos aplicamos el mismo tipo de procesamiento que en otros modelos (ej. KNN). Este consiste en convertir las variables categóricas a numéricas mediante OneHotEncoding y normalizar los datos que correspondan para evitar que ocurra un desvío no deseado al momento de realizar los cálculos. Primero probamos usando el dataframe inicial, sin expandirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rl = conversionAVariablesNormalizadas(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buscamos los mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la búsqueda de los hiperparámetros consideramos que los más importantes eran los siguientes:\n",
    " * **Penalidad**\n",
    " * **C**\n",
    " \n",
    "**Penalidad:** Especifica la penalización del modelo. Probamos con las siguientes regularizaciones 'l1','l2,'elasticnet, y sin regularización.\n",
    "\n",
    "**C:** Es un parámetro que indica qué tan fuerte es la regularización. Similar a SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_regularizacion, mejor_c = obtenerMejoresHiperparametros(X_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"La regularizacion encontrada que maximiza el AUC fue: {mejor_regularizacion}\")\n",
    "print(f\"El valor de C que maximiza el AUC fue: {mejor_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora con la expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = expansionDelDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_codificables_extra = ['pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "columnas_numericas_extra = ['2_clusters','4_clusters','10_clusters','cantidad_total_invitados','total_pagado']\n",
    "\n",
    "X_rl_exp = conversionAVariablesNormalizadas(X,columnas_codificables_extra,columnas_numericas_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor_exp, mejor_regularizacion_exp, mejor_c_exp = obtenerMejoresHiperparametros(X_rl_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {round(mejor_valor_exp,3)}\")\n",
    "print(f\"La regularizacion encontrada que maximiza el AUC fue: {mejor_regularizacion_exp}\")\n",
    "print(f\"El valor de C que maximiza el AUC fue: {mejor_c_exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos una muy ligera mejora. Probamos si se puede agrandar sacandole algunas de las columanas nuevas. Estas son algunas que pueden llegar a ser reduntantes en este modelo. Por ejemplo la cantidad total de invitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_codificables_extra = ['pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "columnas_numericas_extra = ['4_clusters','10_clusters','total_pagado']\n",
    "\n",
    "X_rl_exp2 = conversionAVariablesNormalizadas(X,columnas_codificables_extra,columnas_numericas_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor_exp2, mejor_regularizacion_exp2, mejor_c_exp2 = obtenerMejoresHiperparametros(X_rl_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {round(mejor_valor_exp2,3)}\")\n",
    "print(f\"La regularizacion encontrada que maximiza el AUC fue: {mejor_regularizacion_exp2}\")\n",
    "print(f\"El valor de C que maximiza el AUC fue: {mejor_c_exp2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que mejoro un poco mas. Probamos de armar un modelo nuevo de Regresion Logistica con los hiperparametros encontrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos las métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el set de datos en sets de training y test. Luego creamos el modelo con los hiperparámetros obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rl_exp2, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = None\n",
    "if mejor_regularizacion_exp2 == \"none\":\n",
    "    rl = LogisticRegression(penalty = mejor_regularizacion_exp2,solver = \"saga\",max_iter = 5000)\n",
    "else:\n",
    "    rl = LogisticRegression(penalty = mejor_regularizacion_exp2,l1_ratio = None,  solver = \"saga\", C = mejor_c_exp2,max_iter = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los resultados ahora con las diferentes métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarROCCurve(rl,\"Regresion Logistica\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(rl,\"Regresion Logistica\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que se obtuvo un rendimiento bastante bueno con este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y preparamos el nuevo archivo realizando el mismo preprocesamiento realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = obtenerHoldout()\n",
    "holdout = prepararSetDeHoldout(holdout)\n",
    "holdout = expansionDelDataset(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_codificables_extra = ['pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "columnas_numericas_extra = ['4_clusters','10_clusters','total_pagado']\n",
    "\n",
    "holdout_rl = conversionAVariablesNormalizadas(holdout,columnas_codificables_extra,columnas_numericas_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las predicciones y escribimos al archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_holdout = rl.predict(holdout_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escribirPrediccionesAArchivo(predicciones_holdout,\"RegresionLogistica\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
