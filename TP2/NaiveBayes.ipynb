{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Naive Bayes - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las bibliotecas correspondientes a este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeHoldout\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import conversionAVariablesCodificadas\n",
    "from preprocessing import conversionAVariablesContinuas\n",
    "from preprocessing import expansionDelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo\n",
    "from funcionesAuxiliares import obtenerDatasets\n",
    "from funcionesAuxiliares import obtenerHoldout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación del set de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos ambos set de datos, y se los pasamos a la funciones que realizan el armado hecho para el TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = obtenerDatasets()\n",
    "\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejorAlpha(modelo,datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_alpha = None\n",
    "    y_array=np.array(y)\n",
    "    for valor_alpha in [0.001,0.01,0.1,0.3,0.5,0.7,1,2,3,10]:\n",
    "        kf = StratifiedKFold(n_splits=2)\n",
    "        metricas = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "            modeloNB = modelo(alpha=valor_alpha)\n",
    "            modeloNB.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "            predicciones = modeloNB.predict_proba(datosPreprocesados[test_index])[:, 1]\n",
    "            score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "            metricas.append(score_obtenida)\n",
    "\n",
    "        if np.mean(metricas) >= mejor_valor:\n",
    "            mejor_valor = np.mean(metricas)\n",
    "            mejor_alpha = valor_alpha\n",
    "            \n",
    "    return mejor_valor, mejor_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejorHiperparametroGaussianNB(datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_smoothing = None\n",
    "    y_array=np.array(y)\n",
    "    for valor_smoothing in [0.00000001,0.0000001,0.000001,0.00001,0.0001,0.001]:\n",
    "        kf = StratifiedKFold(n_splits=8)\n",
    "        metricas = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "            modeloNB = GaussianNB(var_smoothing=valor_smoothing)\n",
    "            modeloNB.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "            predicciones = modeloNB.predict_proba(datosPreprocesados[test_index])[:, 1]\n",
    "            score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "            metricas.append(score_obtenida)\n",
    "\n",
    "        if np.mean(metricas) >= mejor_valor:\n",
    "            mejor_valor = np.mean(metricas)\n",
    "            mejor_smoothing = valor_smoothing\n",
    "            \n",
    "    return mejor_valor, mejor_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficarAUCROC(tipo,modeloNB,X_test,X_train,y_test,y_train):\n",
    "    \n",
    "    fpr_nb_test,tpr_nb_test,thresholds_nb_test = roc_curve(y_test,modeloNB.predict_proba(X_test)[:,1])\n",
    "    fpr_nb_train,tpr_nb_train,thresholds_nb_train = roc_curve(y_train,modeloNB.predict_proba(X_train)[:,1])\n",
    "\n",
    "    zero_test = np.argmin(np.abs(thresholds_nb_test))\n",
    "    zero_train = np.argmin(np.abs(thresholds_nb_train))\n",
    "\n",
    "    plt.plot(fpr_nb_train,tpr_nb_train,label=\"ROC Curve \"+tipo+\" NB Train\")\n",
    "    plt.plot(fpr_nb_test,tpr_nb_test,label=\"ROC Curve  \"+tipo+\" NB Test\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.plot(fpr_nb_test[zero_test],tpr_nb_test[zero_test],'o',markersize=10,label=\"threshold zero test\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "    plt.plot(fpr_nb_train[zero_train],tpr_nb_train[zero_train],'x',markersize=10,label=\"threshold zero train\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo es utilizado para problemas de clasificación en los que se tienen variables categóricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos realizando el preprocesamiento a los datos. En este caso consiste en deshacernos de las variables con datos numéricos (ej. precio, edad) y codificar ordinalmente el resto de las variables. Probamos primero quedandonos con todas las categoricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasCategoricas = ['sufijo','tipo_de_sala','genero','fila','nombre_sede']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categoricalNB = conversionAVariablesCodificadas(X,columnasCategoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a hiperparámetros, los modelos de Naive Bayes son simples, ya que solamente tienen un solo hiperparámetro importante, siendo este el alpha. El alpha indica cuanto smoothing se le va a estar aplicando a los diferentes casos, de forma tal de no tener casos con probabilidad 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejor_valor, mejor_alpha = obtenerMejorAlpha(CategoricalNB,X_categoricalNB) \n",
    "# Tira el index out of bounds (index 6 is out of bounds for axis 1 with size 6)\n",
    "\n",
    "#categoricalNBCV = GridSearchCV(CategoricalNB(), {'alpha':[0.001,0.01,0.1,0.3,0.5,0.7,1,2,3,10]}, n_jobs = -1)\n",
    "#categoricalNBCV.fit(X_categoricalNB, y)\n",
    "#categoricalNBCV.predict(X_categoricalNB)\n",
    "#categoricalNBCV.best_params_\n",
    "# Tira el index out of bounds tambien con esto :C (index 6 is out of bounds for axis 1 with size 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor = 1\n",
    "mejor_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora con el preprocesamiento que expande el dataset creando nuevas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = expansionDelDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasCategoricas = ['sufijo','tipo_de_sala','genero','fila','nombre_sede','pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "X_categoricalNB_exp = conversionAVariablesCodificadas(X,columnasCategoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejor_valor_exp, mejor_alpha_exp = obtenerMejorAlpha(CategoricalNB,X_categoricalNB_exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"El mejor valor de AUC fue: {round(mejor_valor_exp,3)}\")\n",
    "#print(f\"El mejor alpha obtenido fue: {mejor_alpha_exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de las métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el set de datos y creamos el modelo con el valor de alpha obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_categoricalNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalNB = CategoricalNB(alpha=mejor_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos ahora las predicciones correspondientes con la parte de entrenamiento y la de pruebas, una vez hecho eso, mostramos las métricas obtenidas en cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = categoricalNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Categorical\",categoricalNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que en este caso la curva de evaluación resulta mejor que la de entrenamiento, indicando que se generalizó mejor. Esto se debe a que se acerca mucho más hacia la esquina superior izquierda del gráfico. (Su área bajo la curva está más cerca de 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(categoricalNB,\"Categorical NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos guardamos las probabilidades que predice este modelo, ya que las usaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_categorical = categoricalNB.predict_proba(X_train)\n",
    "probabilidades_x_test_categorical = categoricalNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos de manera similar para Multinomial Naive Bayes. Este caso solamente difiere en que este modelo se utiliza para features discretos. Por lo que sacamos los atributos que no sirven para este caso y codificamos el resto. Probando los basicos al comienzo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasDiscretas = ['sufijo','tipo_de_sala','genero','amigos','parientes','precio_ticket','fila','nombre_sede']\n",
    "X_multinomialNB = conversionAVariablesCodificadas(X,columnasDiscretas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_alpha = obtenerMejorAlpha(MultinomialNB,X_multinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo obtenido el mejor alpha para el Multinomial Naive Bayes en el preprocesamiento basico, probamos ahora con el expandido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasDiscretas = ['sufijo','tipo_de_sala','genero','amigos','parientes','fila','nombre_sede','precio_ticket','2_clusters','4_clusters','10_clusters',\n",
    "                     'cantidad_total_invitados','pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "X_multinomialNB_exp = conversionAVariablesCodificadas(X,columnasDiscretas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor_exp, mejor_alpha_exp = obtenerMejorAlpha(MultinomialNB,X_multinomialNB_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor_exp,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha_exp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que empeoro el promedio del AUC. Probamos sin algunas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasDiscretas = ['sufijo','tipo_de_sala','genero','amigos','parientes','fila','precio_ticket',\n",
    "                     'cantidad_total_invitados','pago_categorizado','edades_estratificadas','categoria_invitados']\n",
    "X_multinomialNB_exp2 = conversionAVariablesCodificadas(X,columnasDiscretas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor_exp2, mejor_alpha_exp2 = obtenerMejorAlpha(MultinomialNB,X_multinomialNB_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor_exp2,3)}\")\n",
    "print(f\"El mejor alpha obtenido fue: {mejor_alpha_exp2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observo una mejora respecto al primero sacando los resultados de los clusters y de la sede. Probamos un ultimo modelo con las caracteristicas que dieron mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_multinomialNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB = MultinomialNB(alpha=mejor_alpha_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos devuelta las predicciones de la parte de evaluación pero con este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multinomialNB.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, se obtuvieron en la mayoría de las métricas valores cercanos al 80% para ambas predicciones hechas. Vemos la matriz de confusión ahora y el área bajo la curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Multinomial\",multinomialNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que devuelta la curva de evaluación tiene mejor forma que la de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(multinomialNB,\"Multinomial NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso obtuvimos rendimientos bastante similares al del CategoricalNB, estando ligeramente abajo por unas milésimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_multinomial = multinomialNB.predict_proba(X_train)\n",
    "probabilidades_x_test_multinomial = multinomialNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos ahora Gaussian Naive Bayes. Este modelo es para features continuos, por lo que en su preprocesamiento nos quedaremos solamente con ese tipo de variables. Al realizar esto, no esperamos que este modelo tenga un gran rendimiento, ya que estaría considerando una parte reducida de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gaussianNB = conversionAVariablesContinuas(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos el hiperparámetro que tiene este modelo. (var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_var_smoothing = obtenerMejorHiperparametroGaussianNB(X_gaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor var_smoothing obtenido fue: {mejor_var_smoothing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussianNB, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB = GaussianNB(var_smoothing = mejor_var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos lo realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gaussianNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos ahora la curva ROC para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarAUCROC(\"Gaussian\",gaussianNB,X_test,X_train,y_test,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que en este caso se tuvo una curva mucho peor que en los anteriores casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(gaussianNB,\"Gaussian NB\",X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que se obtuvo un valor muy bajo. Esto era esperable, ya que se están analizando muy pocas variables al considerar solamente las continuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_gaussian = gaussianNB.predict_proba(X_train)\n",
    "probabilidades_x_test_gaussian = gaussianNB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Ensamble\" de Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que sklearn tiene la limitación que no permite trabajar a la vez con variables categóricas y variables continuas, decidimos realizar un ensamble al que le pasamos las probabilidades de los 3 modelos hechos anteriormente. De esta forma, logramos obtener un modelo de Naive Bayes que trabaje con ambos tipos de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos uniendo las probabilidades obtenidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_x_train = np.hstack((probabilidades_multinomial, probabilidades_categorical , probabilidades_gaussian))\n",
    "probabilidades_x_test = np.hstack((probabilidades_x_test_multinomial, probabilidades_x_test_categorical , probabilidades_x_test_gaussian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_var_smoothing = obtenerMejorHiperparametroGaussianNB(X_gaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor de AUC fue: {round(mejor_valor,3)}\")\n",
    "print(f\"El mejor var_smoothing obtenido fue: {mejor_var_smoothing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_gaussiano = GaussianNB(var_smoothing = mejor_var_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_gaussiano.fit(probabilidades_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensamble_gaussiano.predict(probabilidades_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(ensamble_gaussiano,\"Ensamble Gaussiano NB\",probabilidades_x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo hecho el ensamble, observamos que no se tuvieron grandes diferencias en comparacion al Multinomial y Categorical, estando este tipo de ensamble en el medio. Lo que sí mejoró notablemente es su rendimiento en comparación al Gaussian NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansión de análisis: estudio del algoritmo y cuáles son los features más relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de Naive Bayes debe calcular, a priori, las probabilidades de que una instancia pertenezca a una clase. Esto lo hace con la variable target, las \"etiquetas\" del set de entrenamiento. De esta manera si inicialmente tenemos más instancias de una clase que de otra tendremos más probabilidad de clasificarla de esa clase mayoritaria, al menos a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNB.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(categoricalNB.class_log_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(multinomialNB.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, dado que hemos entrenado ambos modelos con la misma información de variable target, las probabilidades a priori son las mismas para los tres modelos. Podemos ver que casi dos tercios de la instancias son de la clase \"No volveria\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = X.drop(columns=['edad', 'precio_ticket', 'autocompletamos_edad']).columns.to_list()\n",
    "features_gaussian = ['edad','precio_ticket','autocompletamos_edad']\n",
    "features_multinomial = X.drop(columns=['edad', 'autocompletamos_edad']).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos ahora información acerca de las probabilidades condicionales que se construyeron en el modelo. Analizaremos algunas para poder ver si se corresponden con el análisis realizado en la primer parte del trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for array in categoricalNB.feature_log_prob_:\n",
    "    \n",
    "    feature = features_categorical[i]\n",
    "    for probabilidad in array:\n",
    "        print(feature)\n",
    "        if(j % 2 == 0):\n",
    "            print(\"Dado que no volveria\")\n",
    "        else:\n",
    "            print(\"Dado que volveria\")\n",
    "        print(np.exp(probabilidad))\n",
    "        print(\"\")\n",
    "        j=j+1\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las probabilidades anteriores son las probabilidades condicionales. Condicionado al subconjunto de las personas que volverían o no volverían se calcula para cada feature la probabilidad de que tome alguno de los valores que puede tomar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede calcular utilizando pandas, por ejemplo para el caso del género: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(columns = ['volveria'], data = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_volveria = X.iloc[y_df.loc[y_df[\"volveria\"] == True].index]\n",
    "X_volveria[\"genero\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_volveria = X.iloc[y_df.loc[y_df[\"volveria\"] == False].index]\n",
    "X_no_volveria[\"genero\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que dentro de las personas que volverían, el 70% es mujer y dentro de las personas que no vuelven el 84% es hombre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este feature es bastante relevante. Por ejemplo, suponiendo que consideramos solo este feature realizaríamos las siguientes predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si es hombre:\n",
    "* $P$(vuelve)    = $P_{a priori}$(vuelve) * $P$(hombre|vuelve) = 0.38 * 0.30 = 0.114\n",
    "* $P$(no vuelve) = $P_{a priori}$(no vuelve) * $P$(hombre|no vuelve) = 0.62 * 0.84 = 0.52\n",
    "    \n",
    "P(vuelve) < P(no vuelve) => si es hombre no vuelve\n",
    "    \n",
    "Si es mujer: \n",
    "* $P$(vuelve) = $P_{a priori}$(vuelve) * $P$(mujer|vuelve) = 0.38 * 0.69 = 0.26\n",
    "* $P$(no vuelve) = $P_{a priori}$(no vuelve) * $P$(mujer|no vuelve) = 0.62 * 0.15 = 0.093\n",
    "    \n",
    "    $P$(vuelve) > $P$(no vuelve) => si es mujer vuelve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que relativamente las probabilidades son muy distintas: para los hombres, la probabilidad de que vuelva es aproximadamente 3 veces mayor que de que no vuelva y para las mujeres lo contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por este motivo consideramos que debe ser un feature relevante a la hora de clasificar a una persona en si esta volvería o no al cine a ver la secuela de la película."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones sobre el nuevo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y preparamos el nuevo archivo realizando el mismo preprocesamiento realizado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = obtenerHoldout()\n",
    "holdout = prepararSetDeHoldout(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasCategoricas = ['sufijo','tipo_de_sala','genero','fila','nombre_sede']\n",
    "columnasDiscretas = ['sufijo','tipo_de_sala','genero','amigos','parientes','precio_ticket','fila','nombre_sede']\n",
    "\n",
    "holdout_categorical_NB = conversionAVariablesCodificadas(holdout,columnasCategoricas)\n",
    "holdout_multinomial_NB = conversionAVariablesCodificadas(holdout,columnasDiscretas)\n",
    "holdout_gaussian_NB = conversionAVariablesContinuas(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_holdout_categorical = categoricalNB.predict(holdout_categorical_NB)\n",
    "predicciones_holdout_multinomial = multinomialNB.predict(holdout_multinomial_NB)\n",
    "predicciones_holdout_gaussian = gaussianNB.predict(holdout_gaussian_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escribirPrediccionesAArchivo(predicciones_holdout_categorical,\"Categorical NB\")\n",
    "escribirPrediccionesAArchivo(predicciones_holdout_multinomial,\"Multinomial NB\")\n",
    "escribirPrediccionesAArchivo(predicciones_holdout_gaussian,\"Gaussian NB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
