{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Boosting - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumnos y Padrón**  \n",
    "* Grassano, Bruno - 103855  \n",
    "* Romero, Adrián   - 103371\n",
    "\n",
    "https://github.com/brunograssano/TP-Organizacion-de-datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las bibiliotecas que utilizaremos a lo largo del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcionesAuxiliares import mostrarAUCScore\n",
    "from funcionesAuxiliares import mostrarROCCurve\n",
    "from funcionesAuxiliares import mostrarMatrizDeConfusion\n",
    "from funcionesAuxiliares import escribirPrediccionesAArchivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import prepararSetDeValidacion\n",
    "from preprocessing import arbolDeDecisionPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los datos y los procesamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos que tenemos y llamamos a las funmciones que se encargaran de dejar listos los datasets con la investigacion del TP1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')\n",
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')\n",
    "X = prepararSetDeDatos(X)\n",
    "y = prepararSetDeValidacion(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = arbolDeDecisionPreprocessing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejoresParametros(datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_fc_perdida = None\n",
    "    mejor_lr = None\n",
    "    mejor_cantidad_estimadores = None\n",
    "    mejor_criterio = None\n",
    "    y_array=np.array(y)\n",
    "    for fc_perdida in [\"deviance\", \"exponential\"]:\n",
    "        for lr in [0.1, 0.01, 0.001]:\n",
    "            for cantidad_estimadores in [10, 50, 100, 150]:\n",
    "                for criterio in [\"friedman_mse\", \"mse\", \"mae\"]:\n",
    "                    kf = StratifiedKFold(n_splits=5)\n",
    "                    metricas = []\n",
    "                    for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "                        b = GradientBoostingClassifier(criterion=criterio, loss=fc_perdida, n_estimators=cantidad_estimadores, learning_rate=lr)\n",
    "                        b.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "                        predicciones = b.predict(datosPreprocesados[test_index])\n",
    "                        score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "                        metricas.append(score_obtenida)\n",
    "\n",
    "                    if np.mean(metricas) >= mejor_valor:\n",
    "                        mejor_valor = np.mean(metricas)\n",
    "                        mejor_fc_perdida = fc_perdida\n",
    "                        mejor_lr = lr\n",
    "                        mejor_cantidad_estimadores = cantidad_estimadores\n",
    "                        mejor_criterio = criterio\n",
    "            \n",
    "    return mejor_valor, mejor_fc_perdida, mejor_lr, mejor_cantidad_estimadores, mejor_criterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En boosting se entrena un primer modelo sobre todo el set de entrenamiento. Luego se entrenan modelos subsiguientes a partir de los datos que el modelo anterior predijo mal.  De esta forma la varianza total del ensamble es baja, porque cada modelo entrenado ponderara de forma distinta las observaciones. En general los ensambles tienen bajo sesgo, y en particular boosting logra bajar la varianza. \n",
    "\n",
    "A cada instancia se le asigna inicialmente un peso, luego se predice y se recalculan los pesos, restandole importancia a las bien clasificadas para entrenar al modelo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parametros a definir en Boosting son:\n",
    "\n",
    "**Loss:** la funcion de perdida que se busca optimizar\n",
    "\n",
    "**Learning rate:** es la tasa de aprendizaje con la que se busca optimizar la funcion de perdida anterior.\n",
    "\n",
    "**Numero de estimadores:** es la cantidad de estimadores con los que se entrenara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos el set de datos en sets de training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos los mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_fc_perdida, mejor_lr, mejor_cantidad_estimadores, mejor_criterio = obtenerMejoresParametros(X_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {mejor_valor}\")\n",
    "print(f\"La mejor funcion de perdida encontrada que maximiza el AUC fue: {mejor_fc_perdida}\")\n",
    "print(f\"El mejor learning rate encontrado que maximiza el AUC fue: {mejor_lr}\")\n",
    "print(f\"La mejor cantidad de estimadores que maximiza el AUC fue: {mejor_cantidad_estimadores}\")\n",
    "print(f\"El mejor criterio encontrado que maximiza el AUC fue: {mejor_criterio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos las metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = GradientBoostingClassifier(loss=mejor_fc_perdida, learning_rate=mejor_lr, n_estimators=mejor_cantidad_estimadores, criterion=mejor_criterio)\n",
    "b.fit(X_train, y_train)\n",
    "y_pred = b.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarMatrizDeConfusion(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz podemos ver que tenemos pocos falsos negativos, tan solo 8 y por lo tanto tenemos un muy buen precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarROCCurve(b,\"Boosting\",X_test, X_train, y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrarAUCScore(b,\"Boosting\",X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
