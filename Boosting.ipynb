{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos las bibiliotecas que utilizaremos a lo largo del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import prepararSetDeDatos\n",
    "from preprocessing import arbolDeDecisionPreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los datos y los procesamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Datasets/tp-2020-2c-train-cols2.csv')\n",
    "y = pd.read_csv('Datasets/tp-2020-2c-train-cols1.csv')\n",
    "X,y = prepararSetDeDatos(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = arbolDeDecisionPreprocessing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMejoresParametros(datosPreprocesados):\n",
    "    mejor_valor = 0\n",
    "    mejor_fc_perdida = None\n",
    "    mejor_lr = None\n",
    "    mejor_cantidad_estimadores = None\n",
    "    mejor_criterio = None\n",
    "    y_array=np.array(y)\n",
    "    for fc_perdida in [\"deviance\", \"exponential\"]:\n",
    "        for lr in [0.1, 0.01, 0.001]:\n",
    "            for cantidad_estimadores in [10, 50, 100, 150]:\n",
    "                for criterio in [\"friedman_mse\", \"mse\", \"mae\"]:\n",
    "                    kf = StratifiedKFold(n_splits=5)\n",
    "                    metricas = []\n",
    "                    for fold_idx, (train_index, test_index) in enumerate(kf.split(datosPreprocesados, y_array)):\n",
    "                        b = GradientBoostingClassifier(criterion=criterio, loss=fc_perdida, n_estimators=cantidad_estimadores, learning_rate=lr)\n",
    "                        b.fit(datosPreprocesados[train_index], y_array[train_index].ravel())\n",
    "                        predicciones = b.predict(datosPreprocesados[test_index])\n",
    "                        score_obtenida = roc_auc_score(y_array[test_index],predicciones)\n",
    "                        metricas.append(score_obtenida)\n",
    "\n",
    "                    if np.mean(metricas) >= mejor_valor:\n",
    "                        mejor_valor = np.mean(metricas)\n",
    "                        mejor_fc_perdida = fc_perdida\n",
    "                        mejor_lr = lr\n",
    "                        mejor_cantidad_estimadores = cantidad_estimadores\n",
    "                        mejor_criterio = criterio\n",
    "            \n",
    "    return mejor_valor, mejor_fc_perdida, mejor_lr, mejor_cantidad_estimadores, mejor_criterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos el set de datos en sets de training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscamos los mejores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_valor, mejor_fc_perdida, mejor_lr, mejor_cantidad_estimadores, mejor_criterio = obtenerMejoresParametros(X_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El mejor valor fue de AUC fue: {mejor_valor}\")\n",
    "print(f\"La mejor funcion de perdida encontrada que maximiza el AUC fue: {mejor_fc_perdida}\")\n",
    "print(f\"El mejor learning rate encontrado que maximiza el AUC fue: {mejor_lr}\")\n",
    "print(f\"La mejor cantidad de estimadores que maximiza el AUC fue: {mejor_cantidad_estimadores}\")\n",
    "print(f\"El mejor criterio encontrado que maximiza el AUC fue: {mejor_criterio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos las metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = GradientBoostingClassifier(loss=mejor_fc_perdida, learning_rate=mejor_lr, n_estimators=mejor_cantidad_estimadores, criterion=mejor_criterio)\n",
    "b.fit(X_train, y_train)\n",
    "y_pred = b.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['No vuelve','Vuelve']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi =150)   \n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, vmin = 0, yticklabels=[\"Volveria\",\"No volveria\"], xticklabels=[\"Volveria\", \"No Volveria\"], ax=ax)\n",
    "ax.set_title(\"Matriz de confusi√≥n de Boosting\")\n",
    "ax.set_xlabel(\"Predicho\")\n",
    "ax.set_ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_b_test,tpr_b_test,thresholds_b_test = roc_curve(y_test,b.predict_proba(X_test)[:,1])\n",
    "\n",
    "zero_test = np.argmin(np.abs(thresholds_b_test))\n",
    "\n",
    "plt.plot(fpr_b_test,tpr_b_test,label=\"ROC Curve Boosting Test\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.plot(fpr_b_test[zero_test],tpr_b_test[zero_test],'o',markersize=10,label=\"threshold zero test\",fillstyle=\"none\",c=\"k\",mew=2)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_b = roc_auc_score(y_test,b.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC para Boosting: {:.3f}\".format(auc_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
